% !Mode:: "TeX:UTF-8"

\chapter{实验结果}\label{sec:exp}

这个实验是在一个具有两个8核16线程CPU的linux服务器上进行的，每个CPU主频为2.90GHZ，服务器内存64GB。
新的分层动态热管理方法主要用MATLAB实现。
我们分别构建了四个不同的处理器核配置的众核处理器，从$100$核（$10 \times 10$）到$625$核（$25 \times 25$）。
这些处理器的热模型由HotSpot生成。环境温度设定为$20^{\circ}$C。
在这个实验中众核处理器由完全一致的Alpha 21264核组成。所有芯片的大小都是$10mm \times 10mm \times 0.15mm$。
这里我们假设众核处理器中任务运行时相互之间没有通讯也不需要同步。
任务的功耗由Wattch通过运行SPEC基准程序生成，初始任务分配为，一个任务随机指定给一个核运行。
接下来的任务分配和调度有动态温度管理方法确定。
我们有9个SPEC基准程序的实时功耗信息。
对于不同的处理器的功耗信息，我们重复这9个功耗信息得到处理器需要的100个实时功耗信息，256个实时功耗信息等等。

因为核的大小会随核的数量增长变化，这会超过所谓的“功耗墙”或者“利用率墙”导致不现实的功耗密度，产生极高的温度。
为解决这个问题，提出了很多解决方法。一个解决方案是灰硅，放缩每个核的功耗。另一个更广泛的方法是完全关掉一些核\cite{Taylor:MICRO'13,Shafique:DAC'14}。
在我们的研究中，我们采用灰硅技术，放缩功耗的大小以保证所有处理器都有相似的功耗密度，这样温度分布就类似于现在的多核芯片。
这个可以通过以一定的比例调整操作频率和电压来实现，放缩比例在表~\ref{tab:param}中给出。
在我们的这个研究中，我们并不考虑完全关掉一部分核的策略，这会是我们将来的研究方向。
\begin{table}[H]
\centering
 \begin{tabular}{|c|c|c|c|}
 \hline
 \hline
 处理器核数 &  放缩比例 & $e_{th}$ & $r$ \\
 \hline 
 \hline
 $100$ 核 ($10 \times 10$) & 0.21 & 0.06 & 500  \\
 \hline
 $256$ 核 ($16 \times 16$) & 0.08 & 0.05 & 2100 \\
 \hline
 $400$ 核 ($20 \times 20$) & 0.052 & 0.04 & 3000 \\
 \hline
 $625$ 核 ($25 \times 25$) & 0.033 & 0.03 & 3000 \\
 \hline
 \hline
 \end{tabular}
 \caption{对不同核数处理器在新分层方法的参数}\label{tab:param}
 \end{table}
 
对于不同核数的处理器，为保证温度能有效地趋近顶温度，任务迁移过程中的阈值$e_{th}$和 式 \eqref{eq:cost_fun} 中 MPC调整参数$r$ 需要手动调整。
这里注意，最优的$e_{th}$和$r$值与微处理器核的数量和结构高度相关，理论上没有必要去计算这些参数在实际的。
在实际的应用中，针对一个确定的众核微处理器，很容易通过实验来调整这些参数。
表~\ref{tab:param}给出了这些参数的值。我们可以看出$e_{th}$随功耗模型的大小（在我们的情况中也是核的大小）变化。
如果核的大小相对较大，$e_{th}$ 也需要指定一个相对较大的值（即表~\ref{tab:param}中100核的情况）。反之亦然（即表~\ref{tab:param}中625核的情况）。
这是因为较大的功耗有较大的芯片空间供功耗分布，所以对相同的温度容忍限制，允许有更大的功耗差值。
另一个现象是核数越大，需要较大的$r$值。
这是因为在式\eqref{eq:cost_fun}中，当核数增长的时候$Y_{ceil}-Y_k$ 中的每个元素并没有变化太大，
但是$\Delta P_k$中的每个元素会变得小很多（因为每个核的功耗缩小）。
为了使$\Delta P_k$有更小的解，$r$的值需要变大。
这里注意625核的情况$r$值仍然是$3000$，与 $400$核的情况相同，因为我们发现到这个程度再继续增大$r$值没有明显的影响。

在低层划分上，我们划分每$25$ ($5 \times 5$)个相邻核为一块。
在高层处理中，如果图$\mathcal{G}_p$中的元素数目超过$240$就用改进迭代最小割算法进行分割。

为了最小化任务迁移的开销，任务迁移和DVFS的启动周期设定为$20$s。任务迁移的开销来自于计算核迁移操作。
通常处理器核数较小时，用较小的迁移周期。因为核数少时，计算开销和迁移操作开销（关系到核与核之间的通信）都很小。
对中核处理器情况，因为核数很大，频繁的任务迁移是很难执行的，所以迁移周期延长。迁移间隔内一个核的负载可能会增长很多，这样可能引起超出温度限制。
在这种情况下，我们在迁移间隔内需要保证安全的时候只能执行DVFS。

在实验中，除了任务迁移决策计算的开销，任务迁移操作的开销也要考虑进去。
正常的任务迁移操纵开销大概是$10^6$个时钟周期，对$1$GHZ的处理器大概是 $1$ms\cite{Cuesta:ISVLSI'10}。
因为在众核处理器中核数很大，核之间通信时间很长，这样的开销会很大。
所以我们设定上百核处理器的任务迁移时间为$100$ms。
在实验中我们要考虑任务迁移的功耗。这个功耗由迁移时间内核的通信产生，在迁移时对应的两个核不处理任何任务。
所以我们假设任务迁移时间的功耗小于任务处理时间的功耗。为保证安全，我们将任务迁移时的功耗设定为之前处理任务时的平均功耗，用这样的功耗提供给MPC做预测。

作为比较，我们实现了另外两种基于MPC的方法，众核处理器基于MPC混合任务迁移和DVFS的动态温度管理方法\cite{MaWang:APCCAS'14}和基于MPC只用DVFS的方法。
我们也选择了\cite{Hanumaiah:TCAD'11}中的动态温度管理方法作为对比，因为它和我们的研究有相同的目标，即改性能处理器有温度限制时最大化性能（吞吐量）。
我们在实验中实现了开源项目MAGMA V2，这个由\cite{Hanumaiah:TCAD'11}的作者提供。MAGMA只能给出100核处理器的结果，对于更大的核数情况会有“超出内存”错误。
在这里所有的方法都用相同的激活周期，功耗信息和顶温度。
































